{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('googlejobskills.csv')\n",
    "heads = df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df1['Title']\n",
    "Res = df1['Responsibilities']\n",
    "Qual_min = df1['Minimum Qualifications']\n",
    "Qual_pref = df1['Preferred Qualifications']\n",
    "Qual = ['{}\\n{}'.format(Qual_min[i],Qual_pref[i]) for i in range(len(Res))]\n",
    "Qual_data = pd.DataFrame(data = Qual,columns = ['Qual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.concat([titles,Res,Qual_data],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('datajobposts.csv')\n",
    "heads2 = df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df2['Title']\n",
    "JobDescription = df2['JobDescription']\n",
    "JobRequirment = df2['JobRequirment']\n",
    "RequiredQual = df2['RequiredQual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([titles,JobDescription,RequiredQual],axis = 1, keys = ['Title', 'Responsibilities', 'Qual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data1,data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[pd.isna(data.iloc[:]['Responsibilities']) == True].index)\n",
    "data = data.drop(data[pd.isna(data.iloc[:]['Qual']) == True].index)\n",
    "data = data.drop(data[pd.isna(data.iloc[:]['Title']) == True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array(data)\n",
    "np.save('jobdetail.npy', data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('jobdetail.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDescription = data[1]\n",
    "Title = data[0]\n",
    "JobRequirment = data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from collections import  Counter\n",
    "plt.style.use('ggplot')\n",
    "stop=set(stopwords.words('english'))\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import os\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict={}\n",
    "with open('glove.6B.200d.txt','r') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vectors=np.asarray(values[1:],'float32')\n",
    "        embedding_dict[word]=vectors\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16081/16081 [00:00<00:00, 657304.10it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN=100\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(JobDescription)\n",
    "sequences=tokenizer_obj.texts_to_sequences(JobDescription)\n",
    "job_description_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')\n",
    "word_index=tokenizer_obj.word_index\n",
    "\n",
    "num_words=len(word_index)+1\n",
    "embedding_matrix=np.zeros((num_words,200))\n",
    "\n",
    "for word,i in tqdm(word_index.items()):\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    \n",
    "    emb_vec=embedding_dict.get(word)\n",
    "    if emb_vec is not None:\n",
    "        embedding_matrix[i]=emb_vec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "embedding = Embedding(num_words, 200, weights=[embedding_matrix],trainable=False)\n",
    "model.add(embedding)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Flatten())\n",
    "job_description_embedding = model.predict(job_description_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=1, min_samples=1).fit(job_description_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for label in db.labels_:\n",
    "    if label in dic:\n",
    "        dic[label]+=1\n",
    "    else:\n",
    "        dic[label] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_jobs = [[k, v] for k, v in sorted(dic.items(), key=lambda item: item[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_job = {}\n",
    "for i in range(len(db.labels_)):\n",
    "    label = db.labels_[i]\n",
    "    if label in cluster_to_job:\n",
    "        cluster_to_job[label].append(i)\n",
    "    else:\n",
    "        cluster_to_job[label] = [i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Information Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import urllib\n",
    "import json, codecs\n",
    "import requests\n",
    "\n",
    "def getResponse(url):\n",
    "    \"\"\"\n",
    "    Return response in json format.\n",
    "    \"\"\"\n",
    "    req = Request(url)\n",
    "    response = request.urlopen(req)\n",
    "    data = json.loads(response.read())\n",
    "    return data\n",
    "\n",
    "def getCourseList():\n",
    "    url = \"https://courses.edx.org/api/courses/v1/courses/?page=1\"\n",
    "    courseList = []\n",
    "    while True:\n",
    "        \n",
    "        response = request.urlopen(url)\n",
    "        data = json.loads(response.read())\n",
    "\n",
    "        for course in data['results']:\n",
    "            courseList.append(course['id'])\n",
    "\n",
    "        url = data['pagination']['next']\n",
    "        if url == None:\n",
    "            break\n",
    "    return courseList\n",
    "\n",
    "def parseCourse(rawdata):\n",
    "    baseUrl = \"https://www.edx.org\"\n",
    "    course = []\n",
    "    title = rawdata['title']\n",
    "    description = rawdata['description']\n",
    "    what_to_learn = rawdata['what_you_will_learn']\n",
    "    course = [title,description,what_to_learn]\n",
    "    return course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "courseList = getCourseList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getResponse(url):\n",
    "    \"\"\"\n",
    "    Return response in json format.\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {\"Authorization\": auth}\n",
    "    req = requests.get(url, headers = headers)\n",
    "    data = req.json()\n",
    "    \n",
    "    return data\n",
    "def getCourseDetail(courseList):\n",
    "    baseUrl = \"https://www.edx.org/api/catalog/v2/courses/\"\n",
    "    courseDetail = []\n",
    "    for uri in courseList:\n",
    "        url = baseUrl + uri\n",
    "        try:\n",
    "            response = getResponse(url)\n",
    "        except:\n",
    "            print(url)\n",
    "            continue\n",
    "        if type(response) is dict:\n",
    "            #course = parseCourse(response)\n",
    "            courseDetail.append(response)\n",
    "\n",
    "    return courseDetail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.edx.org/api/catalog/v2/courses/course-v1:edX+PublisherProdTest1+3T2019\n",
      "https://www.edx.org/api/catalog/v2/courses/course-v1:EPFLx+Immuno_1X+3T2019a\n"
     ]
    }
   ],
   "source": [
    "courseDetail = getCourseDetail(courseList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "courseDetail_array = np.array(courseDetail)\n",
    "np.save('coursesdetail.npy', courseDetail_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_data1 = np.load('coursesdetail.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymongo in /Users/XinZhang/Library/Python/3.7/lib/python/site-packages (3.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo\n",
    "import pymongo\n",
    "client = pymongo.MongoClient('mongodb://admin:a123456@ds339648.mlab.com:39648/moocer')\n",
    "db = client.moocer\n",
    "course_data2 = []\n",
    "for x in db.courses.find():\n",
    "    course_data2.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "coursesinfo = []\n",
    "for c in course_data1:\n",
    "    \n",
    "    if (not c['title'] is None) and (not c['description'] is None) and (len(c['description']) > 0) and (not c['what_you_will_learn'] is None) and (len(c['what_you_will_learn']) > 0 ):\n",
    "        coursesinfo.append([c['title'],c['description'],c['what_you_will_learn'],c['course_about_uri'],'edX'])\n",
    "for s in course_data2:\n",
    "    if (not s['title'] is None) and (not s['summary'] is None) and (len(s['summary']) > 0) and (len(s['shortSummary']) > 0):\n",
    "        coursesinfo.append([s['title'],s['summary'],s['shortSummary'],s['url'],s['platform']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(tweet):\n",
    "    # Special characters\n",
    "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
    "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
    "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
    "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
    "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
    "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
    "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n",
    "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\n\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\r\", \"\", tweet)\n",
    "    tweet = re.sub(r\"\\t\", \"\", tweet)\n",
    "    tweet = re.sub(r\"[ ]+\", \" \", tweet)\n",
    "\n",
    "    # Character entity references\n",
    "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
    "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
    "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
    "    \n",
    "    # Urls\n",
    "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
    "    # Words with punctuations and special characters\n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
    "    for p in punctuations:\n",
    "        tweet = tweet.replace(p, f' {p} ')\n",
    "    #remove html tag\n",
    "    html = re.compile(r'<.*?>')\n",
    "    tweet = html.sub(r'',tweet)\n",
    "    return tweet\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "coursesinfo = np.array(coursesinfo)\n",
    "for row in coursesinfo:\n",
    "    row[1] = clean(row[1])\n",
    "    row[2] = clean(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('coursesinfo.npy', coursesinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('coursesinfo.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "courseDescription = data[:,1]\n",
    "courseLearned = data[:,2]\n",
    "courseTitle = data[:,0]\n",
    "courseURL = data[:,3]\n",
    "coursePlat = data[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Word from Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pke\n",
    "def extract_keyphrases(caption, n):\n",
    "    extractor = pke.unsupervised.TextRank() \n",
    "    extractor.load_document(caption)\n",
    "    extractor.candidate_selection()\n",
    "    extractor.candidate_weighting()\n",
    "    keyphrases = extractor.get_n_best(n=n, stemming=False)\n",
    "    return(keyphrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords_from_cluster(label):\n",
    "    indexlist = cluster_to_job[label]\n",
    "    keyskills = {}\n",
    "    for index in indexlist:\n",
    "        requirement = JobRequirment.iloc[index]\n",
    "        keywords = [i[0] for i in extract_keyphrases(requirement,5)]\n",
    "        keywords.append(Title.iloc[index])\n",
    "        for w in keywords:\n",
    "            if w in keyskills:\n",
    "                keyskills[w] += 1\n",
    "            else:\n",
    "                keyskills[w] = 1\n",
    "    out = [[k,keyskills[k]] for k in keyskills]\n",
    "    out = sorted(out, key=second,reverse = True)\n",
    "    topkey = [k[0] for k in out[:10]]\n",
    "\n",
    "    return topkey\n",
    "def second(v):\n",
    "    return v[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 14:01:08.160101 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:01:56.478227 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:02:05.560759 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:02:15.586358 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:02:36.925670 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:02:38.116981 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:02:53.099766 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:02:53.859015 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:02:54.237247 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:02:54.642292 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:02:55.027206 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:02:55.402202 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:03:08.292176 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:03:24.852537 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:03:25.218755 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:03:25.619089 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:03:26.358612 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:03:26.748450 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:03:27.122313 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:03:33.793649 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:03:36.117640 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:03:58.935280 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:04:10.283852 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:04:42.843193 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:05:12.710572 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:05:13.090407 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 14:05:19.795198 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:05:23.308737 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:05:25.249080 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:06:48.877116 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:06:50.080933 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:06:50.467087 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:07:20.863300 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:07:31.127787 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:07:44.667129 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:07:57.808128 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:08:21.684399 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:08:53.366767 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:09:44.724082 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:10:19.743925 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:10:20.540055 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:10:31.723582 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:10:32.106768 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:10:32.489998 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:10:32.883486 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:10:33.691213 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:10:34.071937 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:10:44.102063 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:10:48.572646 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:10:50.945517 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:10:55.765421 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:11:00.086576 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 14:11:02.054737 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:11:35.513275 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:11:40.699024 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:11:41.504777 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:11:43.876716 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:11:47.852056 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:12:43.654925 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:15:17.035385 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:15:17.447028 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:15:28.996389 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:15:29.390991 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:15:32.556398 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:15:37.649448 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:16:24.768344 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:16:37.176129 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:17:43.324790 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 14:18:16.502675 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:18:57.260250 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:19:47.323717 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:23:59.337248 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:25:15.413938 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:25:21.367361 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:28:27.015908 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 14:30:50.584693 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:33:18.170418 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:33:22.951527 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 14:39:14.028560 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:39:56.109847 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 14:45:52.855664 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:46:21.963301 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:48:13.728437 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:48:14.512295 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 14:49:30.092208 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:53:00.417061 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 14:56:25.841331 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 15:02:45.850142 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 15:02:52.274743 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 15:08:23.654018 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 15:10:11.862469 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 15:16:11.629561 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 15:18:50.147486 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 15:18:54.936847 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 15:19:43.186842 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 15:21:42.822494 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 15:21:43.635755 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 15:24:27.884395 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 15:25:23.430272 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 15:26:45.162416 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 15:28:53.738472 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 15:30:09.877207 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 15:39:56.444535 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 15:40:38.144296 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 15:40:56.930804 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 15:42:04.968474 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 15:44:57.847115 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 15:44:59.522420 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 15:45:00.673782 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 15:53:53.936589 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n"
     ]
    }
   ],
   "source": [
    "cluster_to_keyword = {}\n",
    "for label in cluster_to_job:\n",
    "    keyset = keywords_from_cluster(label)\n",
    "    \n",
    "    cluster_to_keyword[label] = keyset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Word From Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 16:06:00.823024 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 16:08:38.822242 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 16:08:40.468400 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:08:40.859536 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:08:48.500175 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:08:49.259229 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:08:49.672231 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 16:08:50.057402 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:12:27.144389 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 16:23:00.984117 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:26:07.556628 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 16:26:09.998987 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 16:26:10.418514 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 16:26:11.212362 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 16:26:14.943423 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 0 given)\n",
      "W0417 16:30:17.262804 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:33:40.213900 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 0 given)\n",
      "W0417 16:33:40.622664 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 0 given)\n",
      "W0417 16:34:59.792453 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:36:52.104432 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:36:53.781925 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 1 given)\n",
      "W0417 16:37:59.105708 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 2 given)\n",
      "W0417 16:38:53.063508 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 16:39:20.444031 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 16:39:21.696866 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n",
      "W0417 16:39:24.131849 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 4 given)\n",
      "W0417 16:39:28.211853 4388984256 base.py:269] Not enough candidates to choose from (5 requested, 3 given)\n"
     ]
    }
   ],
   "source": [
    "course_to_keyword = {}\n",
    "for c in range(len(courseLearned)):\n",
    "    title = courseTitle[c]\n",
    "    if not title in course_to_keyword:\n",
    "        course_to_keyword[title] = [v[0] for v in extract_keyphrases(str(courseDescription[c]),5)]\n",
    "        course_to_keyword[title].append(title)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Cluster and Course Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def related_score(key_skill, key_learn):\n",
    "    token = key_skill.split()\n",
    "    total = len(token)\n",
    "    count = 0\n",
    "    for i in token:\n",
    "        if i in key_learn:\n",
    "            count+=1\n",
    "    return count/total\n",
    "\n",
    "def skillsets_to_course(skillsets):\n",
    "    scoreboard = []\n",
    "    \n",
    "    skill = ' '.join(skillsets)\n",
    "    title = []\n",
    "    content = []\n",
    "    for i in course_to_keyword:\n",
    "        coursekey = course_to_keyword[i]\n",
    "        title.append(i)\n",
    "        content.append(' '.join(coursekey))\n",
    "    content.append(skill)\n",
    "    vec = TfidfVectorizer()\n",
    "    response = vec.fit_transform(content)\n",
    "    out = csr_matrix(response).toarray()\n",
    "    for index in range(len(out) - 1):\n",
    "        scoreboard.append([title[index],cosine_similarity([out[index]],[out[-1]])])\n",
    "    \n",
    "    \n",
    "    output = [v[0] for v in sorted(scoreboard, key=lambda item: item[1], reverse = True)]\n",
    "    return output[:100]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_matching_map = {}\n",
    "for i in cluster_to_keyword:\n",
    "    out = skillsets_to_course(cluster_to_keyword[i])\n",
    "    #clean duplicate:\n",
    "    out_cleaned = []\n",
    "    outset = set()\n",
    "    for t in out:\n",
    "        if (not t.lower() in outset) and check_if_english(t):\n",
    "            outset.add(t.lower())\n",
    "            out_cleaned.append(t)\n",
    "            \n",
    "    \n",
    "    \n",
    "    course_matching_map[i] = out_cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def check_if_english(title):\n",
    "    \n",
    "    for i in title.split():\n",
    "        if not isEnglish(i):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def isEnglish(s):\n",
    "    return s.isascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keyword matching For User (Implemented in the backend of website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n",
    "def key_input_search(key):\n",
    "    max_score = 0.0\n",
    "    index = 0\n",
    "    l = len(Title)\n",
    "    for i in range(l):\n",
    "        if not pd.isna(Title.iloc[i]):\n",
    "            score = textdistance.jaro_winkler(Title.iloc[i].lower(),key.lower())\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                index = i\n",
    "    return db.labels_ [index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_from_dic = {}\n",
    "for i in coursesinfo:\n",
    "    course_from_dic[i[0]] = i[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save course_matching_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "course_matching_map_out = {}\n",
    "for i in course_matching_map:\n",
    "    course_matching_map_out[int(i)] = course_matching_map[i]\n",
    "with open('course_matching_map_out_all_plat.json', 'w') as f:\n",
    "        json.dump(course_matching_map_out, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Cluster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblabels = {}\n",
    "for i in range(len(db.labels_)):\n",
    "    joblabels[i] = int(db.labels_[i])\n",
    "with open('joblabel.json', 'w') as f:\n",
    "        json.dump(joblabels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('joblabel.json', 'r') as f:\n",
    "        check = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitle = {}\n",
    "for i in range(len(titles)):\n",
    "    jobtitle[i] = titles.iloc[i]\n",
    "with open('title.json', 'w') as f:\n",
    "        json.dump(jobtitle, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save course URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_out = {}\n",
    "for i in range(len(courseTitle)):\n",
    "    url_out[courseTitle[i]] = courseURL[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('url_all_plat.json', 'w') as f:\n",
    "        json.dump(url_out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save course Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "plat_out = {}\n",
    "for i in range(len(courseTitle)):\n",
    "    plat_out[courseTitle[i]] = coursePlat[i]\n",
    "with open('platform_all_plat.json', 'w') as f:\n",
    "        json.dump(plat_out, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
